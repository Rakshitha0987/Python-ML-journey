{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99df88d7-0fe7-4a3c-a649-3f0d3d39d3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-15 10:40:44.620849: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-15 10:40:46.854420: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-15 10:40:46.857690: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-15 10:40:52.263054: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m f1_score\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m download_images\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Set up paths\u001b[39;00m\n\u001b[1;32m     15\u001b[0m TRAIN_CSV \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset/train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from src.utils import download_images\n",
    "\n",
    "# Set up paths\n",
    "TRAIN_CSV = 'dataset/train.csv'\n",
    "TEST_CSV = 'dataset/test.csv'\n",
    "OUTPUT_CSV = 'test_out.csv'\n",
    "IMAGE_DIR = 'images/'\n",
    "\n",
    "# Load the dataset\n",
    "train_df = pd.read_csv()\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "\n",
    "# Download images\n",
    "download_images(train_df['image_link'].tolist(), IMAGE_DIR)\n",
    "download_images(test_df['image_link'].tolist(), IMAGE_DIR)\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    return transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Dummy model function (Replace with your model)\n",
    "def predict_image(image_tensor):\n",
    "    # Load a pre-trained model (e.g., ResNet) and run inference\n",
    "    model = torchvision.models.resnet18(pretrained=True)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        # Dummy implementation: return a random prediction\n",
    "        return {'value': '34', 'unit': 'gram'}\n",
    "\n",
    "# OCR to extract text\n",
    "def extract_text_from_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    text = pytesseract.image_to_string(image)\n",
    "    return text\n",
    "\n",
    "# Predictions\n",
    "def predict_entities(df, model):\n",
    "    predictions = []\n",
    "    for index, row in df.iterrows():\n",
    "        image_path = f\"{IMAGE_DIR}/{row['index']}.jpg\"\n",
    "        image_tensor = preprocess_image(image_path)\n",
    "        prediction = model(image_tensor)\n",
    "        if prediction:\n",
    "            formatted_prediction = f\"{prediction['value']} {prediction['unit']}\"\n",
    "        else:\n",
    "            formatted_prediction = \"\"\n",
    "        predictions.append({'index': row['index'], 'prediction': formatted_prediction})\n",
    "    return predictions\n",
    "\n",
    "# Create output DataFrame\n",
    "predictions = predict_entities(test_df, predict_image)\n",
    "output_df = pd.DataFrame(predictions)\n",
    "\n",
    "# Save the output file\n",
    "output_df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "print(\"Predictions saved to\", OUTPUT_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad3329f0-172e-40a5-8bef-3480a413b454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to /home/rguktrkvalley/Desktop/test_out1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from io import BytesIO\n",
    "import re\n",
    "\n",
    "# Load datasets\n",
    "train_data = pd.read_csv('/home/rguktrkvalley/Desktop/train1.csv')\n",
    "test_data = pd.read_csv('/home/rguktrkvalley/Desktop/test1.csv')\n",
    "\n",
    "# Define constants\n",
    "ALLOWED_UNITS = {'gram', 'centimetre', 'millilitre', 'kilogram', 'millimetre', 'ounce', 'litre'}\n",
    "# Function to download images\n",
    "def download_image(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading image: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to perform OCR and extract text from images\n",
    "def extract_text_from_image(image):\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(image)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to clean and process extracted text\n",
    "def clean_extracted_text(text, entity_name):\n",
    "    # Regex to find numbers followed by units\n",
    "    pattern = r'(\\d+\\.?\\d*)\\s*(gram|g|cm|centimeter|ml|ounce|kg|kilogram|litre|mm)'\n",
    "    matches = re.findall(pattern, text.lower())  # Find all matches\n",
    "    \n",
    "    cleaned_results = []\n",
    "    \n",
    "    for match in matches:\n",
    "        number = match[0]\n",
    "        unit = match[1]\n",
    "        # Map shorthand to allowed unit\n",
    "        unit_mapping = {\n",
    "            'g': 'gram',\n",
    "            'cm': 'centimetre',\n",
    "            'ml': 'millilitre',\n",
    "            'kg': 'kilogram',\n",
    "            'mm': 'millimetre',\n",
    "            'ounce': 'ounce',\n",
    "            'litre': 'litre'\n",
    "        }\n",
    "        unit = unit_mapping.get(unit, unit)\n",
    "        if unit in ALLOWED_UNITS:\n",
    "            cleaned_results.append(f\"{number} {unit}\")\n",
    "    \n",
    "    # Ensure that the result aligns with the entity name\n",
    "    if entity_name == 'item_weight':\n",
    "        # Example: refine result if entity_name suggests weight\n",
    "        if cleaned_results:\n",
    "            return cleaned_results[0]\n",
    "    elif entity_name == 'item_volume':\n",
    "        # Example: refine result if entity_name suggests volume\n",
    "        if cleaned_results:\n",
    "            return cleaned_results[0]\n",
    "    # Add more conditions based on entity_name as needed\n",
    "\n",
    "    return cleaned_results[0] if cleaned_results else \"\"\n",
    "\n",
    "# Main processing loop for the test dataset\n",
    "predictions = []\n",
    "for idx, row in test_data.iterrows():\n",
    "    image_url = row['image_link']\n",
    "    img = download_image(image_url)\n",
    "    \n",
    "    if img:\n",
    "        extracted_text = extract_text_from_image(img)\n",
    "        cleaned_text = clean_extracted_text(extracted_text,row['entity_name'])\n",
    "        \n",
    "        # Placeholder logic: This should be replaced by actual entity extraction logic\n",
    "        # Currently just outputting the cleaned text\n",
    "        prediction = cleaned_text\n",
    "        \n",
    "        # Append the prediction to the list\n",
    "        predictions.append({\"index\": row['index'], \"prediction\": prediction})\n",
    "    else:\n",
    "        predictions.append({\"index\": row['index'], \"prediction\": \"\"})\n",
    "        \n",
    "\n",
    "# Convert predictions to DataFrame\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "# Save the predictions to CSV in the required format\n",
    "output_file = '/home/rguktrkvalley/Desktop/test_out1.csv'\n",
    "predictions_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Predictions saved to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
