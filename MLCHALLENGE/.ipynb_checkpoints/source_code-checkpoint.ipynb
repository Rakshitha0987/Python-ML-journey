{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccecea71-f2d2-49eb-9765-4031efb8461a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from utils import download_images\n",
    "from pathlib import Path\n",
    "import pytesseract\n",
    "import re\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(filename='image_processing.log', level=logging.INFO)\n",
    "\n",
    "# OCR-based text extraction using pytesseract\n",
    "def extract_text_from_image(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        text = pytesseract.image_to_string(image)  # Extract text using pytesseract OCR\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting text from image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to extract unit and value from text\n",
    "def extract_value_and_unit(text):\n",
    "    # Regular expression to find numbers followed by units like grams, kg, etc.\n",
    "    pattern = re.compile(r'(\\d+(\\.\\d+)?\\s?(gram|kilogram|kg|g|pound|lb|ounce|oz))', re.IGNORECASE)\n",
    "    matches = pattern.findall(text)\n",
    "    if matches:\n",
    "        return matches[0][0]  # Return the first match (number + unit)\n",
    "    else:\n",
    "        logging.warning(f\"No value and unit found in text: {text}\")\n",
    "        return None\n",
    "\n",
    "# Preprocess images\n",
    "def preprocess_image(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        image = image.resize((224, 224))\n",
    "        image_array = img_to_array(image)\n",
    "        image_array = np.expand_dims(image_array, axis=0)\n",
    "        image_array = tf.keras.applications.resnet50.preprocess_input(image_array)\n",
    "        return image_array\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load the base ResNet50 model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "# Define the model architecture\n",
    "inputs = keras.layers.Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "outputs = keras.layers.Dense(1000, activation='softmax')(x)  # Modify based on the actual classes\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Example: Download images and extract labels\n",
    "train_df = pd.read_csv('/home/rguktrkvalley/Desktop/train1.csv')\n",
    "test_df = pd.read_csv('/home/rguktrkvalley/Desktop/sample_test.csv')\n",
    "\n",
    "download_folder = '/home/rguktrkvalley/Desktop/images'\n",
    "download_images(train_df['image_link'].tolist() + test_df['image_link'].tolist(), download_folder)\n",
    "\n",
    "# Prepare training data\n",
    "train_images = [os.path.join(download_folder, Path(link).name) for link in train_df['image_link']]\n",
    "train_labels = train_df['entity_value'].tolist()\n",
    "\n",
    "# Filter out invalid labels and extract text from images\n",
    "valid_labels = []\n",
    "filtered_images = []\n",
    "\n",
    "for img_path in train_images:\n",
    "    # Step 1: Extract text from the image using OCR\n",
    "    extracted_text = extract_text_from_image(img_path)\n",
    "    \n",
    "    if extracted_text:\n",
    "        # Step 2: Extract the value and unit from the text\n",
    "        value_and_unit = extract_value_and_unit(extracted_text)\n",
    "        \n",
    "        if value_and_unit:\n",
    "            # Log the extracted value and unit\n",
    "            logging.info(f\"Extracted from {img_path}: {value_and_unit}\")\n",
    "            valid_labels.append(value_and_unit)\n",
    "            filtered_images.append(img_path)\n",
    "        else:\n",
    "            logging.warning(f\"No valid value and unit found in {img_path}\")\n",
    "    else:\n",
    "        logging.warning(f\"No text extracted from {img_path}\")\n",
    "\n",
    "# Preprocess the valid images\n",
    "processed_images = []\n",
    "valid_labels_filtered = []\n",
    "\n",
    "for img_path, lbl in zip(filtered_images, valid_labels):\n",
    "    processed_image = preprocess_image(img_path)\n",
    "    if processed_image is not None:\n",
    "        processed_images.append(processed_image)\n",
    "        valid_labels_filtered.append(lbl)\n",
    "\n",
    "# Train the model if valid images are available\n",
    "if valid_labels_filtered and processed_images:\n",
    "    print(f\"Training with {len(processed_images)} images and labels.\")\n",
    "    train_labels_categorical = tf.keras.utils.to_categorical(\n",
    "        [0] * len(valid_labels_filtered),  # Dummy labels for now, adjust for your case\n",
    "        num_classes=1000  # Adjust based on your output classes\n",
    "    )\n",
    "    model.fit(np.concatenate(processed_images),\n",
    "              train_labels_categorical,\n",
    "              epochs=10,\n",
    "              batch_size=32,\n",
    "              validation_split=0.2)\n",
    "else:\n",
    "    logging.error(\"No valid labels or images for training.\")\n",
    "\n",
    "# Generate predictions for test images\n",
    "test_images = [os.path.join(download_folder, Path(link).name) for link in test_df['image_link']]\n",
    "test_preds = []\n",
    "\n",
    "for path in test_images:\n",
    "    processed_image = preprocess_image(path)\n",
    "    if processed_image is not None:\n",
    "        test_preds.append(processed_image)\n",
    "\n",
    "# Save predictions\n",
    "if test_preds:\n",
    "    test_preds_array = model.predict(np.concatenate(test_preds))\n",
    "    \n",
    "    # Format and save the prediction output\n",
    "    output_df = pd.DataFrame({'index': test_df['index']})\n",
    "    output_df['prediction'] = ['Predicted_Class' for _ in test_preds_array]  # Placeholder\n",
    "    output_df.to_csv('/home/rguktrkvalley/Desktop/pertest_out.csv', index=False)\n",
    "else:\n",
    "    logging.error(\"No valid test images processed. Predictions cannot be generated.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
