{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43c7af07-7a57-4f03-9281-716e5e6346ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 21, does not match size of target_names, 65. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 124\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m    123\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val_vectorized)\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# Main processing loop for the test dataset\u001b[39;00m\n\u001b[1;32m    127\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/test/notebookenv/lib/python3.8/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/test/notebookenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2567\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2561\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2562\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2563\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[1;32m   2564\u001b[0m             )\n\u001b[1;32m   2565\u001b[0m         )\n\u001b[1;32m   2566\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2567\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2568\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2569\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2570\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[1;32m   2571\u001b[0m         )\n\u001b[1;32m   2572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2573\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[0;31mValueError\u001b[0m: Number of classes, 21, does not match size of target_names, 65. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "import re\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define constants\n",
    "ALLOWED_UNITS = {'gram', 'centimetre', 'millilitre', 'kilogram', 'millimetre', 'ounce', 'litre'}\n",
    "\n",
    "# Load datasets\n",
    "train_data = pd.read_csv('/home/rguktrkvalley/Desktop/train1.csv')\n",
    "test_data = pd.read_csv('/home/rguktrkvalley/Desktop/sample_test.csv')\n",
    "\n",
    "# Function to download images\n",
    "def download_image(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Ensure we notice bad responses\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        return img\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error downloading image: {e}\")\n",
    "        return None\n",
    "    except IOError as e:\n",
    "        print(f\"Error opening image: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to extract text from image\n",
    "def extract_text_from_image(pil_image):\n",
    "    try:\n",
    "        # Convert PIL image to a format OpenCV can work with\n",
    "        open_cv_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Convert the image to grayscale\n",
    "        gray_image = cv2.cvtColor(open_cv_image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply Gaussian Blur to reduce noise\n",
    "        blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "        \n",
    "        # Use adaptive thresholding to binarize the image\n",
    "        binary_image = cv2.adaptiveThreshold(blurred_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                             cv2.THRESH_BINARY, 11, 2)\n",
    "        \n",
    "        # Use Tesseract to extract text from the processed image\n",
    "        text = pytesseract.image_to_string(binary_image)\n",
    "        \n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to clean and process extracted text\n",
    "def clean_extracted_text(text):\n",
    "    # Regex to find numbers followed by units\n",
    "    pattern = r'(\\d+\\.?\\d*)\\s*(gram|g|cm|centimeter|ml|ounce|kg|kilogram|litre|mm)'\n",
    "    matches = re.findall(pattern, text.lower())  # Find all matches\n",
    "    \n",
    "    cleaned_results = []\n",
    "    \n",
    "    for match in matches:\n",
    "        number = match[0]\n",
    "        unit = match[1]\n",
    "        # Map shorthand to allowed unit\n",
    "        unit_mapping = {\n",
    "            'g': 'gram',\n",
    "            'cm': 'centimetre',\n",
    "            'ml': 'millilitre',\n",
    "            'kg': 'kilogram',\n",
    "            'mm': 'millimetre',\n",
    "            'ounce': 'ounce',\n",
    "            'litre': 'litre'\n",
    "        }\n",
    "        unit = unit_mapping.get(unit, unit)\n",
    "        if unit in ALLOWED_UNITS:\n",
    "            cleaned_results.append(f\"{number} {unit}\")\n",
    "    \n",
    "    return cleaned_results[0] if cleaned_results else \"\"\n",
    "\n",
    "# Feature extraction and preparation of training data\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for idx, row in train_data.iterrows():\n",
    "    image_url = row['image_link']\n",
    "    img = download_image(image_url)\n",
    "    \n",
    "    if img:\n",
    "        extracted_text = extract_text_from_image(img)\n",
    "        cleaned_text = clean_extracted_text(extracted_text)\n",
    "        features.append(cleaned_text)  # Store extracted text as feature\n",
    "        labels.append(row['entity_value'])  # Store the actual entity value\n",
    "\n",
    "# Convert features and labels to DataFrame\n",
    "features_df = pd.DataFrame(features, columns=['extracted_text'])\n",
    "labels_df = pd.DataFrame(labels, columns=['entity_value'])\n",
    "\n",
    "# Convert text labels to numerical values for classification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "labels_encoded = le.fit_transform(labels_df['entity_value'])\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(features_df['extracted_text'], labels_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize the text data\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_val_vectorized = vectorizer.transform(X_val)\n",
    "\n",
    "# Train the Decision Tree Classifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_val_vectorized)\n",
    "print(classification_report(y_val, y_pred, target_names=le.classes_))\n",
    "\n",
    "# Main processing loop for the test dataset\n",
    "predictions = []\n",
    "for idx, row in test_data.iterrows():\n",
    "    image_url = row['image_link']\n",
    "    img = download_image(image_url)\n",
    "    \n",
    "    if img:\n",
    "        extracted_text = extract_text_from_image(img)\n",
    "        cleaned_text = clean_extracted_text(extracted_text)\n",
    "        \n",
    "        # Vectorize the cleaned text for prediction\n",
    "        cleaned_text_vectorized = vectorizer.transform([cleaned_text])\n",
    "        prediction_encoded = model.predict(cleaned_text_vectorized)\n",
    "        \n",
    "        # Decode the prediction back to the original label\n",
    "        prediction = le.inverse_transform(prediction_encoded)[0]\n",
    "        \n",
    "        # Append the prediction to the list\n",
    "        predictions.append({\"index\": row['index'], \"prediction\": prediction})\n",
    "    else:\n",
    "        predictions.append({\"index\": row['index'], \"prediction\": \"\"})\n",
    "\n",
    "# Convert predictions to DataFrame\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "# Save the predictions to CSV in the required format\n",
    "output_file = '/home/rguktrkvalley/Desktop/test_out2.csv'\n",
    "predictions_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f'Predictions saved to {output_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "397b842b-4ffa-4b50-a274-c2fab03b832a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 21, does not match size of target_names, 65. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 124\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m    123\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val_vectorized)\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# Main processing loop for the test dataset\u001b[39;00m\n\u001b[1;32m    127\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/test/notebookenv/lib/python3.8/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/test/notebookenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2567\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2561\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2562\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2563\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[1;32m   2564\u001b[0m             )\n\u001b[1;32m   2565\u001b[0m         )\n\u001b[1;32m   2566\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2567\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2568\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2569\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2570\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[1;32m   2571\u001b[0m         )\n\u001b[1;32m   2572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2573\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[0;31mValueError\u001b[0m: Number of classes, 21, does not match size of target_names, 65. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from io import BytesIO\n",
    "\n",
    "# Define constants\n",
    "ALLOWED_UNITS = {'gram', 'centimetre', 'millilitre', 'kilogram', 'millimetre', 'ounce', 'litre'}\n",
    "\n",
    "# Load datasets\n",
    "train_data = pd.read_csv('/home/rguktrkvalley/Desktop/train1.csv') \n",
    "test_data = pd.read_csv('/home/rguktrkvalley/Desktop/sample_test.csv')   \n",
    "\n",
    "# Function to download images\n",
    "def download_image(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Ensure we notice bad responses\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        return img\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error downloading image: {e}\")\n",
    "        return None\n",
    "    except IOError as e:\n",
    "        print(f\"Error opening image: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to extract text from image\n",
    "def extract_text_from_image(pil_image):\n",
    "    try:\n",
    "        # Convert PIL image to a format OpenCV can work with\n",
    "        open_cv_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Convert the image to grayscale\n",
    "        gray_image = cv2.cvtColor(open_cv_image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply Gaussian Blur to reduce noise\n",
    "        blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "        \n",
    "        # Use adaptive thresholding to binarize the image\n",
    "        binary_image = cv2.adaptiveThreshold(blurred_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                             cv2.THRESH_BINARY, 11, 2)\n",
    "        \n",
    "        # Use Tesseract to extract text from the processed image\n",
    "        text = pytesseract.image_to_string(binary_image)\n",
    "        \n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to clean and process extracted text\n",
    "def clean_extracted_text(text):\n",
    "    # Regex to find numbers followed by units\n",
    "    pattern = r'(\\d+\\.?\\d*)\\s*(gram|g|cm|centimeter|ml|ounce|kg|kilogram|litre|mm)'\n",
    "    matches = re.findall(pattern, text.lower())  # Find all matches\n",
    "    \n",
    "    cleaned_results = []\n",
    "    \n",
    "    for match in matches:\n",
    "        number = match[0]\n",
    "        unit = match[1]\n",
    "        # Map shorthand to allowed unit\n",
    "        unit_mapping = {\n",
    "            'g': 'gram',\n",
    "            'cm': 'centimetre',\n",
    "            'ml': 'millilitre',\n",
    "            'kg': 'kilogram',\n",
    "            'mm': 'millimetre',\n",
    "            'ounce': 'ounce',\n",
    "            'litre': 'litre'\n",
    "        }\n",
    "        unit = unit_mapping.get(unit, unit)\n",
    "        if unit in ALLOWED_UNITS:\n",
    "            cleaned_results.append(f\"{number} {unit}\")\n",
    "    \n",
    "    return cleaned_results[0] if cleaned_results else \"\"\n",
    "\n",
    "# Feature extraction and preparation of training data\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for idx, row in train_data.iterrows():\n",
    "    image_url = row['image_link']\n",
    "    img = download_image(image_url)\n",
    "    \n",
    "    if img:\n",
    "        extracted_text = extract_text_from_image(img)\n",
    "        cleaned_text = clean_extracted_text(extracted_text)\n",
    "        features.append(cleaned_text)  # Store extracted text as feature\n",
    "        labels.append(row['entity_value'])  # Store the actual entity value\n",
    "\n",
    "# Convert features and labels to DataFrame\n",
    "features_df = pd.DataFrame(features, columns=['extracted_text'])\n",
    "labels_df = pd.DataFrame(labels, columns=['entity_value'])\n",
    "\n",
    "# Convert text labels to numerical values for classification\n",
    "le = LabelEncoder()\n",
    "labels_encoded = le.fit_transform(labels_df['entity_value'])\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(features_df['extracted_text'], labels_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_val_vectorized = vectorizer.transform(X_val)\n",
    "\n",
    "# Train the Decision Tree Classifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_val_vectorized)\n",
    "print(classification_report(y_val, y_pred, target_names=le.classes_))\n",
    "\n",
    "# Main processing loop for the test dataset\n",
    "predictions = []\n",
    "for idx, row in test_data.iterrows():\n",
    "    image_url = row['image_link']\n",
    "    img = download_image(image_url)\n",
    "    \n",
    "    if img:\n",
    "        extracted_text = extract_text_from_image(img)\n",
    "        cleaned_text = clean_extracted_text(extracted_text)\n",
    "        \n",
    "        # Vectorize the cleaned text for prediction\n",
    "        cleaned_text_vectorized = vectorizer.transform([cleaned_text])\n",
    "        prediction_encoded = model.predict(cleaned_text_vectorized)\n",
    "        \n",
    "        # Decode the prediction back to the original label\n",
    "        prediction = le.inverse_transform(prediction_encoded)[0]\n",
    "        \n",
    "        # Append the prediction to the list\n",
    "        predictions.append({\"index\": row['index'], \"prediction\": prediction})\n",
    "    else:\n",
    "        predictions.append({\"index\": row['index'], \"prediction\": \"\"})\n",
    "\n",
    "# Convert predictions to DataFrame\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "# Save the predictions to CSV in the required format\n",
    "output_file = 'test_out.csv'  # Update with the correct path\n",
    "predictions_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f'Predictions saved to {output_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e72aaae-bb71-4b97-bf3d-b1fa8b4c75cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 21, does not match size of target_names, 65. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 127\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# Ensure y_val and y_pred are not empty and have matching classes\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_val) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_pred) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo predictions or no validation labels available.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/test/notebookenv/lib/python3.8/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/test/notebookenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2567\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2561\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2562\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2563\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[1;32m   2564\u001b[0m             )\n\u001b[1;32m   2565\u001b[0m         )\n\u001b[1;32m   2566\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2567\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2568\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2569\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2570\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[1;32m   2571\u001b[0m         )\n\u001b[1;32m   2572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2573\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[0;31mValueError\u001b[0m: Number of classes, 21, does not match size of target_names, 65. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from io import BytesIO\n",
    "\n",
    "# Define constants\n",
    "ALLOWED_UNITS = {'gram', 'centimetre', 'millilitre', 'kilogram', 'millimetre', 'ounce', 'litre'}\n",
    "\n",
    "# Load datasets\n",
    "train_data = pd.read_csv('/home/rguktrkvalley/Desktop/train1.csv')\n",
    "test_data = pd.read_csv('/home/rguktrkvalley/Desktop/sample_test.csv')\n",
    "\n",
    "# Function to download images\n",
    "def download_image(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Ensure we notice bad responses\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        return img\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error downloading image: {e}\")\n",
    "        return None\n",
    "    except IOError as e:\n",
    "        print(f\"Error opening image: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to extract text from image\n",
    "def extract_text_from_image(pil_image):\n",
    "    try:\n",
    "        # Convert PIL image to a format OpenCV can work with\n",
    "        open_cv_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Convert the image to grayscale\n",
    "        gray_image = cv2.cvtColor(open_cv_image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply Gaussian Blur to reduce noise\n",
    "        blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "        \n",
    "        # Use adaptive thresholding to binarize the image\n",
    "        binary_image = cv2.adaptiveThreshold(blurred_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                             cv2.THRESH_BINARY, 11, 2)\n",
    "        \n",
    "        # Use Tesseract to extract text from the processed image\n",
    "        text = pytesseract.image_to_string(binary_image)\n",
    "        \n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to clean and process extracted text\n",
    "def clean_extracted_text(text):\n",
    "    # Regex to find numbers followed by units\n",
    "    pattern = r'(\\d+\\.?\\d*)\\s*(gram|g|cm|centimeter|ml|ounce|kg|kilogram|litre|mm)'\n",
    "    matches = re.findall(pattern, text.lower())  # Find all matches\n",
    "    \n",
    "    cleaned_results = []\n",
    "    \n",
    "    for match in matches:\n",
    "        number = match[0]\n",
    "        unit = match[1]\n",
    "        # Map shorthand to allowed unit\n",
    "        unit_mapping = {\n",
    "            'g': 'gram',\n",
    "            'cm': 'centimetre',\n",
    "            'ml': 'millilitre',\n",
    "            'kg': 'kilogram',\n",
    "            'mm': 'millimetre',\n",
    "            'ounce': 'ounce',\n",
    "            'litre': 'litre'\n",
    "        }\n",
    "        unit = unit_mapping.get(unit, unit)\n",
    "        if unit in ALLOWED_UNITS:\n",
    "            cleaned_results.append(f\"{number} {unit}\")\n",
    "    \n",
    "    return cleaned_results[0] if cleaned_results else \"\"\n",
    "\n",
    "# Feature extraction and preparation of training data\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for idx, row in train_data.iterrows():\n",
    "    image_url = row['image_link']\n",
    "    img = download_image(image_url)\n",
    "    \n",
    "    if img:\n",
    "        extracted_text = extract_text_from_image(img)\n",
    "        cleaned_text = clean_extracted_text(extracted_text)\n",
    "        features.append(cleaned_text)  # Store extracted text as feature\n",
    "        labels.append(row['entity_value'])  # Store the actual entity value\n",
    "\n",
    "# Convert features and labels to DataFrame\n",
    "features_df = pd.DataFrame(features, columns=['extracted_text'])\n",
    "labels_df = pd.DataFrame(labels, columns=['entity_value'])\n",
    "\n",
    "# Convert text labels to numerical values for classification\n",
    "le = LabelEncoder()\n",
    "labels_encoded = le.fit_transform(labels_df['entity_value'])\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(features_df['extracted_text'], labels_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_val_vectorized = vectorizer.transform(X_val)\n",
    "\n",
    "# Train the Decision Tree Classifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_val_vectorized)\n",
    "\n",
    "# Ensure y_val and y_pred are not empty and have matching classes\n",
    "if len(y_val) > 0 and len(y_pred) > 0:\n",
    "    print(classification_report(y_val, y_pred, target_names=le.classes_))\n",
    "else:\n",
    "    print(\"No predictions or no validation labels available.\")\n",
    "\n",
    "# Main processing loop for the test dataset\n",
    "predictions = []\n",
    "for idx, row in test_data.iterrows():\n",
    "    image_url = row['image_link']\n",
    "    img = download_image(image_url)\n",
    "    \n",
    "    if img:\n",
    "        extracted_text = extract_text_from_image(img)\n",
    "        cleaned_text = clean_extracted_text(extracted_text)\n",
    "        \n",
    "        # Vectorize the cleaned text for prediction\n",
    "        cleaned_text_vectorized = vectorizer.transform([cleaned_text])\n",
    "        prediction_encoded = model.predict(cleaned_text_vectorized)\n",
    "        \n",
    "        # Decode the prediction back to the original label\n",
    "        prediction = le.inverse_transform(prediction_encoded)[0]\n",
    "        \n",
    "        # Append the prediction to the list\n",
    "        predictions.append({\"index\": row['index'], \"prediction\": prediction})\n",
    "    else:\n",
    "        predictions.append({\"index\": row['index'], \"prediction\": \"\"})\n",
    "\n",
    "# Convert predictions to DataFrame\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "# Save the predictions to CSV in the required format\n",
    "output_file = 'test_out.csv'  # Update with the correct path\n",
    "predictions_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f'Predictions saved to {output_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2480b657-638e-4c85-8d74-b85aaed05977",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-15 18:11:17.453807: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-15 18:11:19.754773: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-15 18:11:25.623686: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import re\n",
    "from transformers import pipeline\n",
    "import easyocr\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Function to download the image\n",
    "def download_image(image_url):\n",
    "    response = requests.get(image_url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    return img\n",
    "\n",
    "# Function to extract text from image using EasyOCR\n",
    "def extract_text_from_image(image):\n",
    "    reader = easyocr.Reader(['en'])  # Load with English language\n",
    "    result = reader.readtext(image, detail=0)\n",
    "    return \" \".join(result)\n",
    "\n",
    "# Pre-trained BERT-based NER pipeline\n",
    "ner_model = pipeline(\"ner\", grouped_entities=True)\n",
    "\n",
    "# Function to extract entities using the NER model\n",
    "def extract_entities(text):\n",
    "    ner_results = ner_model(text)\n",
    "    entities = {}\n",
    "    for entity in ner_results:\n",
    "        entity_text = entity['word']\n",
    "        entity_group = entity['entity_group']\n",
    "        if entity_group in [\"MISC\", \"QUANTITY\"]:\n",
    "            entities[entity_text] = entity_group\n",
    "    return entities\n",
    "\n",
    "# Function to preprocess text and append correct units\n",
    "def preprocess_text(text, entity_name):\n",
    "    value = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", text)\n",
    "    if not value:\n",
    "        return \"\"\n",
    "    value = float(value[0])\n",
    "    if \"weight\" in entity_name.lower():\n",
    "        return f\"{value} gram\"\n",
    "    elif \"dimension\" in entity_name.lower():\n",
    "        return f\"{value} cm\"\n",
    "    elif \"volume\" in entity_name.lower():\n",
    "        return f\"{value} litre\"\n",
    "    elif \"voltage\" in entity_name.lower():\n",
    "        return f\"{value} volt\"\n",
    "    elif \"wattage\" in entity_name.lower():\n",
    "        return f\"{value} watt\"\n",
    "    return \"\"\n",
    "\n",
    "# Function to predict entity value for each image\n",
    "def predict_entity_value(entity_name, image_url):\n",
    "    image = download_image(image_url)\n",
    "    extracted_text = extract_text_from_image(image)\n",
    "    entities = extract_entities(extracted_text)\n",
    "    predicted_value = preprocess_text(extracted_text, entity_name)\n",
    "    return predicted_value\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv('dataset/test.csv')\n",
    "\n",
    "# List to store predictions\n",
    "predictions = []\n",
    "\n",
    "# Iterate through test samples and make predictions\n",
    "for index, row in test_data.iterrows():\n",
    "    image_url = row['image_link']\n",
    "    entity_name = row['entity_name']\n",
    "    predicted_value = predict_entity_value(entity_name, image_url)\n",
    "    predictions.append((row['index'], predicted_value))\n",
    "\n",
    "# Create output DataFrame and save to CSV\n",
    "output_df = pd.DataFrame(predictions, columns=[\"index\", \"prediction\"])\n",
    "output_df.to_csv('test_out.csv', index=False)\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "439645eb-b758-4430-8398-d28ac7e1a9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting easyocr\n",
      "  Using cached easyocr-1.7.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: torch in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from easyocr) (2.4.1)\n",
      "Requirement already satisfied: torchvision>=0.5 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from easyocr) (0.19.1)\n",
      "Collecting opencv-python-headless (from easyocr)\n",
      "  Using cached opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: scipy in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from easyocr) (1.10.1)\n",
      "Requirement already satisfied: numpy in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from easyocr) (1.24.3)\n",
      "Requirement already satisfied: Pillow in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from easyocr) (10.2.0)\n",
      "Collecting scikit-image (from easyocr)\n",
      "  Using cached scikit_image-0.21.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting python-bidi (from easyocr)\n",
      "  Using cached python_bidi-0.6.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: PyYAML in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from easyocr) (6.0.1)\n",
      "Collecting Shapely (from easyocr)\n",
      "  Using cached shapely-2.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting pyclipper (from easyocr)\n",
      "  Using cached pyclipper-1.3.0.post5-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting ninja (from easyocr)\n",
      "  Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: filelock in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from torch->easyocr) (3.16.0)\n",
      "Collecting typing-extensions>=4.8.0 (from torch->easyocr)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: sympy in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from torch->easyocr) (1.13.2)\n",
      "Requirement already satisfied: networkx in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from torch->easyocr) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from torch->easyocr) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from torch->easyocr) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from torch->easyocr) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from torch->easyocr) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from torch->easyocr) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from torch->easyocr) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from torch->easyocr) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from torch->easyocr) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from torch->easyocr) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from torch->easyocr) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from torch->easyocr) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from torch->easyocr) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from torch->easyocr) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from torch->easyocr) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->easyocr) (12.6.68)\n",
      "Collecting imageio>=2.27 (from scikit-image->easyocr)\n",
      "  Using cached imageio-2.35.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image->easyocr)\n",
      "  Using cached tifffile-2023.7.10-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting PyWavelets>=1.1.1 (from scikit-image->easyocr)\n",
      "  Using cached PyWavelets-1.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: packaging>=21 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from scikit-image->easyocr) (23.2)\n",
      "Collecting lazy_loader>=0.2 (from scikit-image->easyocr)\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from jinja2->torch->easyocr) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from sympy->torch->easyocr) (1.3.0)\n",
      "Using cached easyocr-1.7.1-py3-none-any.whl (2.9 MB)\n",
      "Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
      "Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m476.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:04\u001b[0m\n",
      "\u001b[?25hDownloading pyclipper-1.3.0.post5-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (682 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m682.3/682.3 kB\u001b[0m \u001b[31m425.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m344.0 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_bidi-0.6.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
      "Downloading scikit_image-0.21.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m42.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:06\u001b[0mm eta \u001b[36m0:00:12\u001b[0m\n",
      "\u001b[?25hDownloading shapely-2.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m62.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m60.8 kB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[?25hDownloading imageio-2.35.1-py3-none-any.whl (315 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading PyWavelets-1.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m92.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:02\u001b[0mm eta \u001b[36m0:00:05\u001b[0mm\n",
      "\u001b[?25hDownloading tifffile-2023.7.10-py3-none-any.whl (220 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: python-bidi, pyclipper, ninja, typing-extensions, tifffile, Shapely, PyWavelets, opencv-python-headless, lazy_loader, imageio, scikit-image, easyocr\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.5.0\n",
      "    Uninstalling typing_extensions-4.5.0:\n",
      "      Successfully uninstalled typing_extensions-4.5.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.13.1 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.12.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyWavelets-1.4.1 Shapely-2.0.6 easyocr-1.7.1 imageio-2.35.1 lazy_loader-0.4 ninja-1.11.1.1 opencv-python-headless-4.10.0.84 pyclipper-1.3.0.post5 python-bidi-0.6.0 scikit-image-0.21.0 tifffile-2023.7.10 typing-extensions-4.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip install easyocr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b177034c-fa2d-464d-961f-67baa4b939ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (4.44.2)\n",
      "Requirement already satisfied: filelock in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from transformers) (3.16.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from transformers) (0.24.7)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from requests->transformers) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/rguktrkvalley/test/notebookenv/lib/python3.8/site-packages (from requests->transformers) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
