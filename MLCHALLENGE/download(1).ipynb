{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ccd49b-5961-468c-9ebb-a17920ae408c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: downloaded_images/default_image.jpg\n",
      "Downloaded: downloaded_images/default_image.jpg\n",
      "Downloaded: downloaded_images/default_image.jpg\n",
      "Downloaded: downloaded_images/default_image.jpg\n",
      "Downloaded: downloaded_images/default_image.jpg\n",
      "Downloaded: downloaded_images/default_image.jpg\n",
      "Downloaded: downloaded_images/default_image.jpg\n",
      "Downloaded: downloaded_images/default_image.jpg\n",
      "Downloaded: downloaded_images/default_image.jpg\n"
     ]
    }
   ],
   "source": [
    "# Downloading images\n",
    "\n",
    "import csv\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# Define the CSV file name\n",
    "csv_file_name = ('/home/apiiit123/ml/student_resource_3/dataset/train.csv')\n",
    "\n",
    "# Create a directory to save downloaded images\n",
    "download_directory = 'downloaded_images'\n",
    "os.makedirs(download_directory, exist_ok=True)\n",
    "\n",
    "# Open the CSV file and read the image URLs\n",
    "with open('/home/apiiit123/ml/student_resource_3/dataset/train.csv', 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    \n",
    "    for row in reader:\n",
    "        # Assuming the URL is in a column named 'image_link'\n",
    "        url = row['image_link']\n",
    "        \n",
    "        # Create a filename based on another column (e.g., 'filename')\n",
    "        filename = row.get('filename', 'default_image')  # Use 'default_image' if 'filename' is not provided\n",
    "        file_path = os.path.join(download_directory, f\"{filename}.jpg\")\n",
    "        \n",
    "        try:\n",
    "            # Download the image\n",
    "            urllib.request.urlretrieve(url, file_path)\n",
    "            print(f\"Downloaded: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download {url}. Reason: {e}\")\n",
    "\n",
    "print(\"Image download process completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d701802-6a93-4b4e-9933-d647bd22c05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image\n",
    "from PIL import Image\n",
    "\n",
    "# Load the image\n",
    "img = Image.open('/home/apiiit123/ml/downloaded_images/default_image.jpg')\n",
    "\n",
    "# Display the image\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed76b982-30f6-4a6e-a00e-507963d7c96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Preprocessing\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "# Define the directory containing images\n",
    "image_dir = '/home/apiiit123/ml/downloaded_images'  # Change this to your image directory\n",
    "processed_images_dir = 'processed_images'\n",
    "os.makedirs(processed_images_dir, exist_ok=True)\n",
    "\n",
    "# Parameters\n",
    "target_size = (150, 150)  # Desired size for resizing\n",
    "batch_size = 32  # Batch size for data augmentation\n",
    "\n",
    "# Function to preprocess and save images\n",
    "def preprocess_images(image_dir):\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            img_path = os.path.join(image_dir, filename)\n",
    "            # Load image\n",
    "            img = load_img(img_path, target_size=target_size)\n",
    "            img_array = img_to_array(img)\n",
    "            img_array = img_array / 255.0  # Normalize to [0, 1]\n",
    "            \n",
    "            # Save processed image\n",
    "            processed_img_path = os.path.join(processed_images_dir, filename)\n",
    "            cv2.imwrite(processed_img_path, img_array * 255)  # Convert back to [0, 255] for saving\n",
    "\n",
    "# Preprocess images\n",
    "preprocess_images(image_dir)\n",
    "\n",
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Example of using the data generator\n",
    "sample_image = load_img(os.path.join(processed_images_dir, 'default_image.jpg'), target_size=target_size)\n",
    "sample_image_array = img_to_array(sample_image)\n",
    "sample_image_array = np.expand_dims(sample_image_array, axis=0)\n",
    "\n",
    "# Generate augmented images\n",
    "augmented_images = datagen.flow(sample_image_array, batch_size=1)\n",
    "\n",
    "# Save augmented images\n",
    "for i in range(5):  # Generate and save 5 augmented images\n",
    "    augmented_image = next(augmented_images)[0]\n",
    "    cv2.imwrite(os.path.join(processed_images_dir, f'augmented_image_{i}.jpg'), augmented_image)\n",
    "\n",
    "print(\"Image preprocessing and augmentation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c4a58a0-9969-41ae-b4e2-33f4cbe3bc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text:\n",
      "EASY wild\n",
      "SQUEEZY!\n",
      "\n",
      "168 DROPPERS 1DROPPERFUL f{ 3) 56-DAY\n",
      "\n",
      "per bottle (1 bulb squeeze)\n",
      "serving size\n",
      "\n",
      " \n",
      "\n",
      "     \n",
      "  \n",
      "\n",
      "SUPPLEMENT FACTS\n",
      "Serving size: 0.7 ml / Servings about 168\n",
      "Amount Per Serving %DV\n",
      "\n",
      "Organic Mullein Leaf 679mg *\n",
      "(Verbascum thapsus)\n",
      "\n",
      "* Daily Value (DV) not established\n",
      "\n",
      "Other Ingredients: Certified Organic\n",
      "vegetable glycerin, distilled water.\n",
      "Does not contain: Alcohol, Sugar.\n",
      "\n",
      " \n",
      "     \n",
      " \n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image, ImageFilter\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Set the path to the Tesseract executable\n",
    "#pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "# Load the image using OpenCV\n",
    "image_path = '/home/apiiit123/ml/downloaded_images/default_image.jpg'  # Replace with your image path\n",
    "image = cv2.imread(image_path)\n",
    "    \n",
    "# Convert the image to grayscale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "# Apply Gaussian Blur to reduce noise\n",
    "blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "    \n",
    "# Use adaptive thresholding to binarize the image\n",
    "binary_image = cv2.adaptiveThreshold(blurred_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                         cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "# Save the processed image (optional, for debugging)\n",
    "cv2.imwrite('processed_image.jpg', binary_image)\n",
    "    \n",
    "# Use Tesseract to extract text from the processed image\n",
    "text = pytesseract.image_to_string(binary_image)\n",
    "    \n",
    "# Print the extracted text\n",
    "print(\"Extracted Text:\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "732a1b7d-fa15-4ea2-a55c-72019d070cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load datasets\n",
    "train_data = pd.read_csv('/home/apiiit123/ml/train1.csv')\n",
    "test_data = pd.read_csv('/home/apiiit123/ml/test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fd7fbaf-363c-4aab-88b8-cc737a6a95df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "ALLOWED_UNITS = {'gram', 'centimetre', 'millilitre', 'kilogram', 'millimetre', 'ounce', 'litre'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "505216a8-d625-4fb4-9110-c8fd6a9d127e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'entity_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m         cleaned_results\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumber\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Ensure that the result aligns with the entity name\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mentity_name\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_weight\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# Example: refine result if entity_name suggests weight\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cleaned_results:\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;28mprint\u001b[39m(cleaned_results[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'entity_name' is not defined"
     ]
    }
   ],
   "source": [
    "# Function to clean and process extracted text\n",
    "    # Regex to find numbers followed by units\n",
    "pattern = r'(\\d+\\.?\\d*)\\s*(gram|g|cm|centimeter|ml|ounce|kg|kilogram|litre|mm)'\n",
    "matches = re.findall(pattern, text.lower())  # Find all matches\n",
    "    \n",
    "cleaned_results = []\n",
    "    \n",
    "for match in matches:\n",
    "    number = match[0]\n",
    "    unit = match[1]\n",
    "    # Map shorthand to allowed unit\n",
    "    unit_mapping = {\n",
    "        'g': 'gram',\n",
    "        'cm': 'centimetre',\n",
    "        'ml': 'millilitre',\n",
    "        'kg': 'kilogram',\n",
    "        'mm': 'millimetre',\n",
    "        'ounce': 'ounce',\n",
    "        'litre': 'litre'\n",
    "    }\n",
    "    unit = unit_mapping.get(unit, unit)\n",
    "    if unit in ALLOWED_UNITS:\n",
    "        cleaned_results.append(f\"{number} {unit}\")\n",
    "    \n",
    "# Ensure that the result aligns with the entity name\n",
    "if entity_name == 'item_weight':\n",
    "    # Example: refine result if entity_name suggests weight\n",
    "    if cleaned_results:\n",
    "        print(cleaned_results[0])\n",
    "elif entity_name == 'item_volume':\n",
    "    # Example: refine result if entity_name suggests volume\n",
    "    if cleaned_results:\n",
    "        print(cleaned_results[0])\n",
    "# Add more conditions based on entity_name as needed\n",
    "\n",
    "print(cleaned_results[0] if cleaned_results else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56535550-a77a-489a-aa7c-b0ab1f50fbdc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'download_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m test_data\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m      4\u001b[0m     image_url \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_link\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_image\u001b[49m(image_url)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m img:\n\u001b[1;32m      8\u001b[0m         extracted_text \u001b[38;5;241m=\u001b[39m extract_text_from_image(image_url)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'download_image' is not defined"
     ]
    }
   ],
   "source": [
    "# Main processing loop for the test dataset\n",
    "predictions = []\n",
    "for idx, row in test_data.iterrows():\n",
    "    image_url = row['image_link']\n",
    "    img = download_image(image_url)\n",
    "    \n",
    "    if img:\n",
    "        extracted_text = extract_text_from_image(image_url)\n",
    "        cleaned_text = clean_extracted_text(extracted_text, row['entity_name'])\n",
    "        \n",
    "        prediction = cleaned_text\n",
    "        \n",
    "        # Append the prediction to the list\n",
    "        predictions.append({\"index\": row['index'], \"prediction\": prediction})\n",
    "    else:\n",
    "        predictions.append({\"index\": row['index'], \"prediction\": \"\"})\n",
    "# Convert predictions to DataFrame\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "# Save the predictions to CSV in the required format\n",
    "output_file = '/home/rguktrkvalley/Desktop/test_out.csv'\n",
    "predictions_df.to_csv(output_file, index=False)\n",
    "# Convert predictions to DataFrame\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "print(f'Predictions saved to {output_file}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
